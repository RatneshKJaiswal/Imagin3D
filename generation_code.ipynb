{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T09:36:38.272717Z",
     "start_time": "2025-03-01T09:36:35.018242Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\working\\imagin3d\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\working\\imagin3d\\.venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in c:\\working\\imagin3d\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\working\\imagin3d\\.venv\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: open3d in c:\\working\\imagin3d\\.venv\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: transformers in c:\\working\\imagin3d\\.venv\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: json5 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: tqdm in c:\\working\\imagin3d\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from torch) (75.8.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: dash>=2.6.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from open3d) (2.18.2)\n",
      "Requirement already satisfied: werkzeug>=3.0.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from open3d) (3.0.6)\n",
      "Requirement already satisfied: flask>=3.0.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from open3d) (3.0.3)\n",
      "Requirement already satisfied: nbformat>=5.7.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from open3d) (5.10.4)\n",
      "Requirement already satisfied: configargparse in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from open3d) (1.7)\n",
      "Requirement already satisfied: ipywidgets>=8.0.4 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from open3d) (8.1.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: colorama in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from dash>=2.6.0->open3d) (6.0.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from dash>=2.6.0->open3d) (5.0.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from dash>=2.6.0->open3d) (8.6.1)\n",
      "Requirement already satisfied: retrying in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from dash>=2.6.0->open3d) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from flask>=3.0.0->open3d) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (3.0.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from nbformat>=5.7.0->open3d) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: decorator in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.6.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.23.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (308)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (1.28.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.21.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision numpy matplotlib open3d transformers json5 tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "631a9d35dcd11e2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T11:22:03.261114Z",
     "start_time": "2025-03-01T11:21:59.463967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\working\\imagin3d\\.venv\\lib\\site-packages (1.15.2)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\working\\imagin3d\\.venv\\lib\\site-packages (from scipy) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e348d935fc752411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:03:24.012450Z",
     "start_time": "2025-03-03T20:03:12.904779Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io  # Replacing h5py with scipy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import ViTModel\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# Enable automatic mixed precision for faster training\n",
    "torch.backends.cudnn.benchmark = True  # Optimizes CUDA performance\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "# Optimized Dataset\n",
    "class Pix3DDataset(Dataset):\n",
    "    def __init__(self, json_path, root_dir, transform=None):\n",
    "        with open(json_path, \"r\") as file:\n",
    "            self.data = json.load(file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        img_path = os.path.join(self.root_dir, sample[\"img\"])\n",
    "        voxel_path = os.path.join(self.root_dir, sample[\"voxel\"])\n",
    "\n",
    "        # Load and transform image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Load voxel data using scipy\n",
    "        voxel_data = scipy.io.loadmat(voxel_path)[\"voxel\"]\n",
    "        voxel_data = torch.tensor(voxel_data, dtype=torch.float32)\n",
    "\n",
    "        return image, voxel_data\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset = Pix3DDataset(\"/home/user/Imagin3D/pix3d.json\", \"/home/user/Imagin3D\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63522092cf8ad28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:03:25.605684Z",
     "start_time": "2025-03-03T20:03:25.595583Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class Simple3DModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple3DModel, self).__init__()\n",
    "        self.encoder = ViTModel.from_pretrained(\"\")\n",
    "        self.fc = nn.Linear(768, 128*128*128)  # Adjust output size to match voxel dimensions\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x).last_hidden_state[:, 0, :]\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, 128, 128, 128)  # Reshape for voxel output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15ef368e955e1ad4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-03T20:03:27.141711Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch [1/10]:  18%|▏| 56/315 [02:05<09:03,  2.10s/it, accuracy=91.9, loss=0.079]/apps/compilers/anaconda3-gpu/lib/python3.11/site-packages/PIL/Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Epoch [1/10]: 100%|█| 315/315 [11:20<00:00,  2.16s/it, accuracy=93.3, loss=0.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0596, Accuracy: 93.29%\n",
      "Model saved with lower loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]: 100%|█| 315/315 [11:16<00:00,  2.15s/it, accuracy=94.7, loss=0.058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0441, Accuracy: 94.66%\n",
      "Model saved with lower loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]: 100%|█| 315/315 [11:06<00:00,  2.12s/it, accuracy=95.4, loss=0.031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0372, Accuracy: 95.43%\n",
      "Model saved with lower loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]: 100%|█| 315/315 [11:08<00:00,  2.12s/it, accuracy=96.3, loss=0.024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0313, Accuracy: 96.32%\n",
      "Model saved with lower loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]: 100%|█| 315/315 [11:06<00:00,  2.11s/it, accuracy=96.8, loss=0.027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0273, Accuracy: 96.84%\n",
      "Model saved with lower loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]: 100%|█| 315/315 [11:06<00:00,  2.11s/it, accuracy=97.3, loss=0.021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0237, Accuracy: 97.26%\n",
      "Model saved with lower loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]: 100%|█| 315/315 [11:02<00:00,  2.10s/it, accuracy=97.6, loss=0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0211, Accuracy: 97.57%\n",
      "Model saved with lower loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]: 100%|█| 315/315 [11:05<00:00,  2.11s/it, accuracy=97.8, loss=0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0192, Accuracy: 97.80%\n",
      "Model saved with lower loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]: 100%|█| 315/315 [11:04<00:00,  2.11s/it, accuracy=98, loss=0.0133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0176, Accuracy: 98.00%\n",
      "Model saved with lower loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]: 100%|█| 315/315 [11:03<00:00,  2.11s/it, accuracy=98.1, loss=0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0165, Accuracy: 98.12%\n",
      "Model saved with lower loss.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Simple3DModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-8)  # Optimized Adam params\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "for epoch in range(10):  # Number of epochs\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    optimizer.zero_grad()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (images, voxels) in enumerate(loop):\n",
    "        images, voxels = images.to(device, non_blocking=True), voxels.to(device, non_blocking=True)  # Enable non_blocking memory transfer\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):  # Enable mixed precision training\n",
    "            predictions = model(images)\n",
    "            loss = criterion(predictions, voxels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        total += voxels.numel()\n",
    "        correct += ((predictions > 0.5) == (voxels > 0.5)).sum().item()  # Binary voxel accuracy\n",
    "        \n",
    "        loop.set_description(f\"Epoch [{epoch+1}/10]\")\n",
    "        loop.set_postfix(loss=loss.item(), accuracy=100.0 * correct / total)\n",
    "    \n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    avg_accuracy = 100.0 * correct / total\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.2f}%\")\n",
    "    \n",
    "    # Save model if it achieves the best loss\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), \"optimized_lrgt_3d_reconstruction.pth\")\n",
    "        print(\"Model saved with lower loss.\")"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:31:00.060251Z",
     "start_time": "2025-03-12T09:28:07.735087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from transformers import ViTModel\n",
    "import scipy.ndimage\n",
    "\n",
    "# Model definition\n",
    "class Simple3DModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple3DModel, self).__init__()\n",
    "        self.encoder = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        self.fc = torch.nn.Linear(768, 128*128*128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x).last_hidden_state[:, 0, :]\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, 128, 128, 128)\n",
    "\n",
    "def visualize_voxel_grid(voxel_data, threshold=0.3):\n",
    "    voxel_data = (voxel_data > threshold).astype(np.uint8)  # Lower threshold\n",
    "    voxel_indices = np.argwhere(voxel_data)\n",
    "    \n",
    "    # Check if we have any points before creating point cloud\n",
    "    if len(voxel_indices) == 0:\n",
    "        print(f\"No voxels detected with threshold {threshold}. Try lowering the threshold value.\")\n",
    "        return None\n",
    "        \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(voxel_indices)\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    return pcd\n",
    "\n",
    "def smooth_voxel_data(voxel_data, threshold=0.3, sigma=1.2):\n",
    "    \"\"\"\n",
    "    Apply Gaussian smoothing to voxel data before thresholding\n",
    "    \"\"\"\n",
    "    # Print statistics about the voxel data\n",
    "    print(f\"Voxel statistics: min={voxel_data.min()}, max={voxel_data.max()}, mean={voxel_data.mean()}\")\n",
    "    print(f\"Number of voxels > 0.5: {np.sum(voxel_data > 0.5)}\")\n",
    "    print(f\"Number of voxels > 0.3: {np.sum(voxel_data > 0.3)}\")\n",
    "    print(f\"Number of voxels > 0.1: {np.sum(voxel_data > 0.1)}\")\n",
    "    \n",
    "    # Apply Gaussian smoothing to the raw voxel predictions\n",
    "    smoothed_data = scipy.ndimage.gaussian_filter(voxel_data, sigma=sigma)\n",
    "    \n",
    "    # Apply threshold after smoothing\n",
    "    binary_voxels = smoothed_data > threshold\n",
    "    \n",
    "    return binary_voxels\n",
    "\n",
    "def save_as_smooth_mesh(voxel_data, filename=\"smooth_output.obj\", threshold=0.3, \n",
    "                        sigma=1.2, depth=9, scale=1.1, linear_fit=False):\n",
    "    \"\"\"\n",
    "    Convert voxel data to a smooth mesh using Poisson surface reconstruction\n",
    "    \n",
    "    Parameters:\n",
    "        voxel_data: numpy array of voxel predictions\n",
    "        filename: output filename\n",
    "        threshold: value threshold for binary voxel decision (lowered from 0.5 to 0.3)\n",
    "        sigma: smoothing factor for Gaussian filter\n",
    "        depth: depth parameter for Poisson reconstruction (higher = more detail)\n",
    "        scale: scale factor for the reconstructed mesh\n",
    "        linear_fit: whether to use linear fit for color interpolation\n",
    "    \"\"\"\n",
    "    # Apply smoothing to the voxel data\n",
    "    binary_voxels = smooth_voxel_data(voxel_data, threshold, sigma)\n",
    "    \n",
    "    # Extract voxel indices where value > threshold\n",
    "    voxel_indices = np.argwhere(binary_voxels)\n",
    "    \n",
    "    if voxel_indices.size == 0:\n",
    "        print(f\"No voxels detected after thresholding with threshold={threshold}. Try lowering the threshold value further.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(voxel_indices)} voxels after thresholding at {threshold}\")\n",
    "    \n",
    "    # Convert voxel indices to point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(voxel_indices.astype(np.float32))\n",
    "    \n",
    "    # Estimate normals with consistent orientation\n",
    "    # Increased parameters for better normal estimation\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=5, max_nn=50))\n",
    "    pcd.orient_normals_consistent_tangent_plane(k=30)\n",
    "    \n",
    "    # Apply Poisson surface reconstruction (produces smoother results than ball pivoting)\n",
    "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
    "        pcd, depth=depth, scale=scale, linear_fit=linear_fit)\n",
    "    \n",
    "    # Optional: Remove low-density vertices which are often outliers\n",
    "    vertices_to_remove = densities < np.quantile(densities, 0.01)\n",
    "    mesh.remove_vertices_by_mask(vertices_to_remove)\n",
    "    \n",
    "    # Final mesh cleanup and preparation\n",
    "    mesh.compute_vertex_normals()\n",
    "    \n",
    "    # Optional: Apply Laplacian smoothing for even smoother results\n",
    "    mesh = mesh.filter_smooth_laplacian(number_of_iterations=5)\n",
    "    \n",
    "    # Save the final mesh\n",
    "    o3d.io.write_triangle_mesh(filename, mesh)\n",
    "    print(f\"Saved smooth 3D model as {filename}\")\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "# Function to predict 3D model from a single image with improved smoothing\n",
    "def predict_smooth_3d_from_image(image_path, model, device, transform, \n",
    "                               output_filename=\"smooth_output.obj\", threshold=0.3):\n",
    "    \"\"\"\n",
    "    Generate a smooth 3D model from a single image\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        print(f\"Successfully loaded image from {image_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        return None\n",
    "        \n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    print(f\"Image tensor shape: {image_tensor.shape}\")\n",
    "    \n",
    "    # Generate prediction\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            predicted_voxel = model(image_tensor).cpu().numpy().squeeze()\n",
    "            print(f\"Successfully generated voxel prediction with shape: {predicted_voxel.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during model prediction: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Add debug information\n",
    "    print(f\"Voxel statistics: min={predicted_voxel.min()}, max={predicted_voxel.max()}, mean={predicted_voxel.mean()}\")\n",
    "    print(f\"Number of voxels > 0.5: {np.sum(predicted_voxel > 0.5)}\")\n",
    "    print(f\"Number of voxels > 0.3: {np.sum(predicted_voxel > 0.3)}\")\n",
    "    print(f\"Number of voxels > 0.1: {np.sum(predicted_voxel > 0.1)}\")\n",
    "    \n",
    "    # If no voxels above threshold, try with a lower threshold\n",
    "    if np.sum(predicted_voxel > threshold) == 0:\n",
    "        print(f\"No voxels above threshold {threshold}, trying with lower threshold 0.1\")\n",
    "        new_threshold = 0.1\n",
    "        if np.sum(predicted_voxel > new_threshold) == 0:\n",
    "            print(\"Still no voxels detected. The model might not be generating valid predictions.\")\n",
    "            return None\n",
    "        else:\n",
    "            threshold = new_threshold\n",
    "    \n",
    "    # Save and visualize the smoothed prediction\n",
    "    mesh = save_as_smooth_mesh(predicted_voxel, filename=output_filename, threshold=threshold)\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "# Main execution function\n",
    "def generate_smooth_3d_model(image_path, model_path, output_path=\"smooth_output.obj\", threshold=0.3):\n",
    "    \"\"\"\n",
    "    Complete pipeline to generate a smooth 3D model from an image\n",
    "    \"\"\"\n",
    "    # Set up device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load the trained model\n",
    "    try:\n",
    "        model = Simple3DModel().to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "        print(f\"Successfully loaded model from {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Define image transformation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    # Generate the smooth 3D model\n",
    "    mesh = predict_smooth_3d_from_image(image_path, model, device, transform, \n",
    "                                       output_path, threshold=threshold)\n",
    "    \n",
    "    # Visualize the result if mesh was created successfully\n",
    "    if mesh is not None:\n",
    "        try:\n",
    "            o3d.visualization.draw_geometries([mesh])\n",
    "        except Exception as e:\n",
    "            print(f\"Error visualizing mesh: {e}\")\n",
    "    else:\n",
    "        print(\"Failed to generate valid mesh\")\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = r\"C:\\Working\\Imagin3D\\data\\img\\sofa\\0158.jpeg\"  # Replace with your image path\n",
    "    model_path = r\"models\\optimized_lrgt_3d_reconstruction.pth\"  # Path to your trained model\n",
    "    output_path = r\"C:\\Working\\Imagin3D\\smooth_output.obj\"  # Where to save the smooth model\n",
    "    \n",
    "    # Try with a lower threshold\n",
    "    generate_smooth_3d_model(image_path, model_path, output_path, threshold=0.2)"
   ],
   "id": "b8da669cf242a642",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from models\\optimized_lrgt_3d_reconstruction.pth\n",
      "Successfully loaded image from C:\\Working\\Imagin3D\\data\\img\\sofa\\0158.jpeg\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Successfully generated voxel prediction with shape: (128, 128, 128)\n",
      "Voxel statistics: min=-0.19323106110095978, max=1.2068321704864502, mean=0.10854323953390121\n",
      "Number of voxels > 0.5: 221367\n",
      "Number of voxels > 0.3: 233847\n",
      "Number of voxels > 0.1: 277531\n",
      "Voxel statistics: min=-0.19323106110095978, max=1.2068321704864502, mean=0.10854323953390121\n",
      "Number of voxels > 0.5: 221367\n",
      "Number of voxels > 0.3: 233847\n",
      "Number of voxels > 0.1: 277531\n",
      "Found 265889 voxels after thresholding at 0.2\n",
      "Saved smooth 3D model as C:\\Working\\Imagin3D\\smooth_output.obj\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "1246bacd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T12:36:01.881074Z",
     "start_time": "2025-03-08T12:35:16.262333Z"
    }
   },
   "source": [
    "import open3d as o3d\n",
    "\n",
    "def view_obj_file(filename=\"output.obj\"):\n",
    "    mesh = o3d.io.read_triangle_mesh(filename)\n",
    "    mesh.compute_vertex_normals()\n",
    "    o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "# Example usage\n",
    "view_obj_file(r\"C:\\Working\\Imagin3D\\output.obj\")  # Replace with your file path"
   ],
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
